{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksamen i videregående økonometri - Januar 2019 \n",
    "#### Aalborg Universitet - cand.oecon\n",
    "Lars Børty Nielsen - Andreas Gravers Klitgaard - Jens Stoustrup Ehmsen\n",
    "\n",
    "\n",
    "- **Opgave 1** Huspriser i Norden: Kointegration [25%]\n",
    "- **Opgave 2** Huspriser i Norden: Forecasting [15%]\n",
    "- **Opgave 3** ARCH-in-mean [10%]\n",
    "- **Opgave 4** Vektorautoregressive modeller [50%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages(library(tidyverse)) # Readr, ggplot, dplyr, ...\n",
    "suppressMessages(library(gridExtra)) # Arrangning ggplots\n",
    "suppressMessages(library(readxl))    # Loading excel\n",
    "suppressMessages(library(repr))      # Resizing the plots in jupyter\n",
    "suppressMessages(library(rugarch))   # For ARCH and GARCH models\n",
    "suppressMessages(library(dynlm))     # Lagged linear models\n",
    "suppressMessages(library(urca))      # Dick Fuller test\n",
    "suppressMessages(library(car))       # Linear hyphothesis testing\n",
    "suppressMessages(library(tseries))   # Adf-test\n",
    "suppressMessages(library(vars))      # VAR models\n",
    "suppressMessages(library(zoo))       # Convert quarters to date\n",
    "suppressMessages(library(forecast))  # Help in plotting TS\n",
    "suppressMessages(library(fGarch))    # The library Lasse uses to do GARCH\n",
    "suppressMessages(library(expm))      # Matrix calculations \n",
    "suppressMessages(library(tsDyn))     # VECM models\n",
    "\n",
    "options(repr.plot.width=8, repr.plot.height=2.5, warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Opgave 1** Huspriser i Norden: Kointegration [25%]\n",
    "\n",
    "#### **Spørgsmål 1.1** Formel definition af kointegration\n",
    "\n",
    "Kointegration omhandler grundlæggende, at to eller flere ikke-stationære variable kan have en fælles stokastisk trend, og der kan derfor findes en lineær kombination af disse variable, som er stationær og dermed udligner de respektive stokastiske trends. Hvis dette er tilfældet, så siges disse variable at være kointegrerede. Det gælder desuden, at kointegrerede variable skal være integreret af samme orden. Man kan således ikke have kointegration mellem en variabel der følger en 𝐼(1)-proces, og en variabel der følger en 𝐼(2)-proces. \n",
    "\n",
    "Hvis vi således har en vektor $x_t$ der indeholder alle de respektive variable fra kointegrationen: $x_t=(x_{1p},x_{2p}.,x_{nt})$. Disse variable siges i denne forbindelse at være integreret af orden d. Ydermere gælder det, at hvis disse variable er kointegrerede, så gælder det, at der eksisterer en vektor $\\beta=(\\beta_1,\\beta_2,., \\beta_n)$ så den lineære kombination $\\beta x_t=\\beta_1 x_{1t}+\\beta_2 x_{2t} + ... \\beta_n x_nt$ af de kointegrerede variable $x_t$ er integreret af orden $d-b$, hvor $b>0$ eller at $\\beta' x_t I~(d-b)$. Denne $\\beta$-vektor kaldes derfor for kointegrationsvektoren. \n",
    "\n",
    "Hvis vi har et eksempel hvor $z_t ~ I(d)$ og $y_t ~ I(d)$ er kointegrerede, så vil disse altså være kointegreret ved $x_t=(z_t,y_t ) ~ CI(b,d)$\n",
    "\n",
    "En central karakteristika ved kointegrerede variable er desuden, at deres tidsserier vil være påvirket af eventuelle afvigelser fra de to variables langsigtede ligevægt. Denne langsigtede ligevægt fås ved at regressere de kointegrerede variable på hinanden. Hvis disse to variable skal bevæge sig tilbage mod deres langsigtede ligevægt, så må mindst en af variablene i kointegrationen reagere på denne afvigelse. Til at beskrive denne tilpasning opstilles såkaldte fejlkorrektionsmodeller. Er der således kointegration mellem to variable, så vil der også være en fejlkorrektionsmodel, som sikre at tidsserierne for de respektive variable vil bevæge sig i retning af den langsigtede ligevægt.\n",
    "\n",
    "Hvis vi fortsat tager udgangspunkt i eksemplet med $y_t$ og $z_t$, så kunne et eksempel på en langsigtet ligevægt være $y_t = ?? + \\beta z_t + u_t$, og så vil en fejlkorrektionsmodel til denne kointegration være:\n",
    "\n",
    "$$\\Delta y=\\alpha_1 (y_{t-1}-\\mu-\\beta z_{t-1} )+v_{yt}$$\n",
    "\n",
    "$$\\Delta z=\\alpha_2 (y_{t-1}-\\mu-\\beta z_{t-1} )+v_{zt}$$\n",
    "\n",
    "Det gælder i denne forbindelse at $\\alpha_1<0$ og $\\alpha_1>0$ og disse to størrelser kaldes for tilpasningshastighederne, da de illustrerer hvor hurtigt de to tidsserier vil bevæge sig tilbage mod den langsigtede ligevægt. Har vi således et scenarier, hvor et stød forårsager at $y_(t-1)> ??-\\beta z_(t-1)$, så kan tilpasningen enten ske ved at $y_t$ falder, $z_t$ stiger eller at begge de to tidsserier ændrer sig. Er de to variable kointegreret, så vil de to tidsserier altså bevæge sig mod den langsigtede ligevægt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 1.2** Intuitativ forklaring af kointegration\n",
    "På baggrund af ovenstående vil der således være tale om kointegration, når to eller flere variable har en fælles stokastisk trend. Har disse variable en fælles stokastisk, så kan der findes en lineær kombination af disse variable, som er stationær og dermed udligner de respektive stokastiske trends. Denne kointegration opstår således, hvis vi kan regressere disse variable på hinanden og at fejlledene for denne regression er stationære. Denne regression mellem variablene vil desuden udtrykke disse variables langsigtede ligevægt. I modsætning til spuriøs regression, så vil kointegration altså være en meningsfuld regression mellem to eller flere ikke-stationære tidsserier. Man kan dog, som nævnt tidligere, ikke have en kointegration mellem variable af forskellige ordner. Indenfor økonomisk analyse vil langt størstedelen af de variable vi arbejder med imidlertid ofte være 𝐼(1)-processer. \n",
    "\n",
    "En central karakteristika ved kointegrerede variable er desuden, at deres tidsserier vil være påvirket af eventuelle afvigelser fra de to variables langsigtede ligevægt (fra regressionen). Visuelt vil man dog ikke altid kunne se på to tidsserier, at de er kointegrerede, da de i nogle tilfælde bare vil bevæge sig væk fra hinanden over den tidsperiode, som man datamæssigt har til rådighed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 1.3** Test af stationaritet\n",
    "*Plot de 3 prisindeks og foretag test for stationaritet af de 3 indeks. Husk at beskrive din fremgangsmåde og hvordan du kommer frem til konklussionen, herunder nulhypotesen, kritiske værdier og en eksplicit specifikation af dine regressionsligninger*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "var <- read_delim(\"C:/Users/larsn/Desktop/var.csv\", \n",
    "    \";\", escape_double = FALSE, locale = locale(decimal_mark = \",\"), \n",
    "    col_type = cols(dato = col_character(),\n",
    "                    DEN = col_double(),\n",
    "                    SWE = col_double(),\n",
    "                    NOR = col_double()),\n",
    "    trim_ws = TRUE)\n",
    "\n",
    "var$dato <- seq(as.Date(\"1975-01-01\"), length = 174, by = \"quarter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vi starter med at plotte de tre tidsserier for at grafisk inspeciere dem. Her ser de ikke ud til at hverken have en konstant varians, eller at følge \n",
    "2. Vi følger general to specific fremgangsmåden, og finder hhv. 5, 8 og 11 lags er passende for modellen for Danmark, Sverige og Norge.\n",
    "3. Vi præsenterer Dickey Fuller fremgangsmådel som vi følger for Danmark som et eksempel\n",
    "  - Vi finder at i en model med drift og trend (reg1) hverken kan afvise unit root ved $\\tau_t$, $\\phi_2$ eller $\\phi_3$ og dermed kan vi ikke afvise at serien indeholder en unit root.\n",
    "  - For modellen med kun drift (reg2) kan vi heller ikke afvise $\\tau_\\mu$ eller $\\phi_1$\n",
    "  - Modellen uden drift (reg3) kan vi heller ikke afvise unit root for $\\gamma$ ved $\\tau$ kritiske værdier (Denne har vi opskrevet)\n",
    "4. Vi konkulderer derfor at det danske boligprisindeks er en unit root process, altså den indeholder en stokastisk trend. \n",
    "  - Det samme gælder for Norge og Sverige, de endelige modelspecifikationer er præsenteret herunder:\n",
    "\n",
    "\n",
    "**Endelige model for Danmark**\n",
    "\n",
    "$$\n",
    "\\Delta DEN_t = \\gamma DEN_{t-1} + \\beta_1\\Delta DEN_{t-1} + \\beta_2\\Delta DEN_{t-2} + \\beta_3\\Delta DEN_{t-3} + \\beta_4\\Delta DEN_{t-4} + \\beta_5\\Delta DEN_{t-5} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "**Endelige model for Sverige**\n",
    "\n",
    "$$\n",
    "\\Delta SWE_t = \\mu + \\gamma SWE_{t-1} + \\beta_1\\Delta SWE_{t-1} + \\beta_2\\Delta SWE_{t-2} + \\beta_3\\Delta SWE_{t-3} + \\beta_4\\Delta SWE_{t-4} + \\beta_5\\Delta SWE_{t-5} + \\beta_6\\Delta SWE_{t-6} + \\beta_7\\Delta SWE_{t-7} + \\beta_8\\Delta SWE_{t-8} + \\beta_9\\varepsilon_t\n",
    "$$\n",
    "\n",
    "**Endelige model for Norge**\n",
    "\n",
    "$$\n",
    "\\Delta NOR_t = \\mu + \\gamma NOR_{t-1} + \\beta_1\\Delta NOR_{t-1} + \\beta_2\\Delta NOR_{t-2} + \\beta_3\\Delta NOR_{t-3} + \\beta_4\\Delta NOR_{t-4} + \\beta_5\\Delta NOR_{t-5} + \\beta_6\\Delta NOR_{t-6} + \\beta_7\\Delta NOR_{t-7} + \\beta_8\\Delta NOR_{t-8} + \\beta_9\\Delta NOR_{t-9} + \\beta_{10}\\Delta NOR_{t-10} + \\beta_{11}\\Delta NOR_{t-11} + \\beta_9\\varepsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): kan ikke starte png()-enhed\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): kan ikke starte png()-enhed\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): kan ikke starte png()-enhed\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): kan ikke starte png()-enhed\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 <- var %>% \n",
    "  gather(variable, value, -dato) %>% \n",
    "  ggplot(aes(dato, value, linetype=variable)) +\n",
    "  geom_line() + \n",
    "  labs(title=\"Boligprisindeks for Danmark Norge og Sverige\", x=\"\", y=\"Prisindeks\")\n",
    "\n",
    "DEN <- as.ts(var$DEN);SWE <- as.ts(var$SWE);NOR <- as.ts(var$NOR)\n",
    "lDEN <- diff(DEN);lSWE <- diff(SWE);lNOR <- diff(NOR)\n",
    "\n",
    "p2 <- data.frame(dato = var$dato[-1], lDEN, lSWE, lNOR) %>% \n",
    "  gather(variable, value, -dato) %>% \n",
    "  ggplot(aes(dato, value)) +\n",
    "  geom_line() + \n",
    "  scale_y_continuous() +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"Differensen til Boligprisindeks for Danmark Norge og Sverige\", x=\"\", y=\"Prisindeks\")\n",
    "\n",
    "print(p1); print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmented Dickey Fuller test**\n",
    "$$\n",
    "\\Delta y_t = a_0 + \\gamma y_{t-1} + a_2t + \\sum^p_{i=2}\\beta_i\\Delta y_{t-i+1} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "**Dickey Fuller test**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Delta y_t = a_0 + \\gamma y_{t-1} + a_2t + \\varepsilon_t \\qquad \\qquad\n",
    "\\gamma &= 0 \\qquad \\tau_1 \\\\\n",
    "a_2 = \\gamma &= 0 \\qquad \\phi_3 \\\\\n",
    "a_0 = a_2 = \\gamma &= 0 \\qquad \\phi_2 \\\\\n",
    "\\\\\n",
    "\\Delta y_t = a_0 + \\gamma y_{t-1} + \\varepsilon_t \\qquad \\qquad\n",
    "\\gamma &= 0 \\qquad \\tau_2 \\\\\n",
    "a_0 = \\gamma  &= 0 \\qquad \\phi_1 \\\\\n",
    "\\\\\n",
    "\\Delta y_t = \\gamma y_{t-1} + \\varepsilon_t \\qquad \\qquad\n",
    "\\gamma &= 0 \\qquad \\tau_3 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(dynlm(lDEN ~ L(DEN) + L(lDEN) + L(lDEN,2) + L(lDEN,3) + L(lDEN,4) + L(lDEN,5)))\n",
    "#summary(dynlm(lSWE ~ L(SWE) + L(lSWE) + L(lSWE,2) + L(lSWE,3) + L(lSWE,4) + L(lSWE,5) + L(lSWE,6) + L(lSWE,7) + L(lSWE,8)))\n",
    "#summary(dynlm(lNOR ~ L(NOR) + L(lNOR) + L(lNOR,2) + L(lNOR,3) + L(lNOR,4) + L(lNOR,5) + L(lNOR,6) + L(lNOR,7) + L(lNOR,8) + L(lNOR,9) + L(lNOR,10) + L(lNOR,11)))\n",
    "\n",
    "# Regressioner for ADF for Danmark\n",
    "reg1 <- dynlm(lDEN ~ L(DEN) + seq_along(lDEN) + L(lDEN) + L(lDEN, 2) + L(lDEN, 3) + L(lDEN, 4) + L(lDEN, 5))\n",
    "reg2 <- dynlm(lDEN ~ L(DEN) + L(lDEN) + L(lDEN, 2) + L(lDEN, 3) + L(lDEN, 4) + L(lDEN, 5))\n",
    "reg3 <- dynlm(lDEN ~ 0 + L(DEN) + L(lDEN) + L(lDEN, 2) + L(lDEN, 3) + L(lDEN, 4) + L(lDEN, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De tre modeller for Danmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 <- summary(reg1)$coefficients[\"L(DEN)\", \"t value\"]\n",
    "p3 <- linearHypothesis(reg1, c(\"L(DEN) = 0\", \"seq_along(lDEN) = 0\", \"(Intercept) = 0\"), test=\"F\")$F[2]\n",
    "p2 <- linearHypothesis(reg1, c(\"L(DEN) = 0\", \"seq_along(lDEN) = 0\"), test=\"F\")$F[2]\n",
    "cv1 <- summary(ur.df(y=DEN, type=\"trend\"))@cval\n",
    "\n",
    "t2 <- summary(reg2)$coefficients[\"L(DEN)\", \"t value\"]\n",
    "p1 <- linearHypothesis(reg2, c(\"L(DEN) = 0\", \"(Intercept) = 0\"), test=\"F\")$F[2]\n",
    "cv2 <- summary(ur.df(y=DEN, type=\"drift\"))@cval\n",
    "\n",
    "t3 <- summary(reg3)$coefficients[\"L(DEN)\", \"t value\"]\n",
    "cv3 <- summary(ur.df(y=DEN, type=\"none\"))@cval\n",
    "\n",
    "df <- as.data.frame(rbind(cbind(test = c(t1,p3,p2), cv1),cbind(test=c(t2,p1), cv2), cbind(test=c(t3),cv3)))\n",
    "df$significant <- ifelse(abs(df$test)>abs(df$\"5pct\"), \"TRUE\", \"FALSE\")\n",
    "\n",
    "rbind(as.matrix(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Til sidst tester vi alle med adf.test og finder at vi ikke kan afvise unit root i nogen af tidsserierne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbind(adf.test(var$DEN, k = 5), \n",
    "      adf.test(var$SWE, k = 8), \n",
    "      adf.test(var$NOR, k = 11))[,c(1:4,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 1.4** Kointegration - Engel Granger\n",
    "*Er de 3 boligprisindeks kointegreret? Brug Engle-Granger fremgangsmåden samlet på de 3 indeks. Redegør for din fremgangsmåde og hvordan du kommer frem til konklussionen, herunder dine valg af deterministiske komponenter i regressionen, kritiske værdier og en eksplicit specifikation af dine regressionsligninger.*\n",
    "\n",
    "Engel Granger metodologien består af 4 steps, men de første 2 er nok til at afgøre om serierne cointegrerer:\n",
    "\n",
    "1. Test efter unitroot med Augmented Dickey Fuller test \n",
    "\n",
    "Dette er gjort i foregående opgave og det viste at alle tre variabler er integreret af første orden I(1)\n",
    "  \n",
    "2. Estimer den langsigtede ligevægt med OLS, se på signifikansen af interceptet og om residualet er stationært (her kan de ordinære ADF fordelinger ikke anvendes, vi har derfor simuleret de kritiske værdier med Monte Carlo simulering)\n",
    "\n",
    "Vores udgangspunkt er en langsigtet sammenhæng i form af modellen: (Der findes tre forskellige, men vi tager udgangspunkt i Danmark som uafhængig variabel)\n",
    "\n",
    "**Langsigtede ligevægt**\n",
    "$$ DANMARK_t = \\beta_0 + \\beta_{1}NORGE_t + \\beta_{2}SVERIGE_t + e_t$$\n",
    "\n",
    "**Sikrer stationært residual - Dickey Fuller**\n",
    "$$ \\Delta\\hat{e_t} = a_1\\hat{e}_{t-1} + \\varepsilon_t $$\n",
    "\n",
    "**Sikrer stationært residual - Augmented Dickey Fuller**\n",
    "$$ \\Delta\\hat{e_t} = a_1\\hat{e}_{t-1} \\sum^{n}_{i=1}a_{i+1}\\Delta\\hat{e}_{t-i}+ \\varepsilon_t $$\n",
    "\n",
    "Interceptet er meget signifikant, og test for residualet med DF med Engel-Granger fordeling skal være mindre end -3.802 (3 variabler, 174 observationer og drift) for at kunne afvise en unit root og derfor konkludere at residualet er ikke stationært, estimatet er -1.273, Da vi ikke kan kan forkaste en unit root anvender vi ADF. Vi finder at lag længden er 6 (jf. general to specific), og med dette er t-værdien på modellen -2.687, hvilket ikke ændrer konklusionen, variablerne er ikke cointegrerede.\n",
    "\n",
    "Vi ved dog at i Engel-Granger metodologien er valget af den unafhængige variabel vigtig, og vi førsøger derfor med både Norge og Sverige som ufafhængig i den langsigtede ligevægt. Vi finder her at med ADF kan vi konludere at variablerne er cointegrerede af orden CI(1,1) (-5.313 for Sverige og -4.843 for Norge, begge ved 6 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(DEN ~ SWE + NOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan ikke anvende den normale t-statistik, og anvender derfor følgendende simulerede kritiske værdier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG3 <- NA\n",
    "for (i in 1:5000) {\n",
    "    x1 <- as.ts(cumsum(rnorm(174)))\n",
    "    x2 <- as.ts(cumsum(rnorm(174)))\n",
    "    x3 <- as.ts(cumsum(rnorm(174)))\n",
    "    res <- as.ts(lm(x1 ~ x2 + x3)$residuals)\n",
    "    a <- summary(dynlm(res ~ L(res)))\n",
    "    EG3[i] <- (a$coefficients[\"L(res)\", \"Estimate\"] - 1)/a$coefficients[\"L(res)\", \"Std. Error\"]\n",
    "}\n",
    "rbind(quantile(EG3, probs = c(0.01,0.05,0.10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg <- lm(DEN ~ SWE + NOR)\n",
    "res <- as.ts(reg$residuals); dres <- diff(res)\n",
    "a1 <- summary(dynlm(dres ~ L(res,1)))$coefficients[\"L(res, 1)\", \"t value\"]\n",
    "b1 <- summary(dynlm(dres ~ L(res,1) + L(dres,1)  + L(dres,2)  + L(dres,3)  + L(dres,4)  + L(dres,5)  + L(dres,6)))$coefficients[\"L(res, 1)\", \"t value\"]\n",
    "\n",
    "reg <- lm(SWE ~ DEN + NOR)\n",
    "res <- as.ts(reg$residuals); dres <- diff(res)\n",
    "a2 <- summary(dynlm(dres ~ L(res,1)))$coefficients[\"L(res, 1)\", \"t value\"]\n",
    "b2 <- summary(dynlm(dres ~ L(res,1) + L(dres,1)  + L(dres,2)  + L(dres,3)  + L(dres,4)  + L(dres,5)  + L(dres,6)))$coefficients[\"L(res, 1)\", \"t value\"]\n",
    "\n",
    "reg <- lm(NOR ~ DEN + SWE)\n",
    "res <- as.ts(reg$residuals); dres <- diff(res)\n",
    "a3 <- summary(dynlm(dres ~ L(res,1)))$coefficients[\"L(res, 1)\", \"t value\"]\n",
    "b3 <- summary(dynlm(dres ~ L(res,1) + L(dres,1)  + L(dres,2)  + L(dres,3)  + L(dres,4)  + L(dres,5)  + L(dres,6)))$coefficients[\"L(res, 1)\", \"t value\"]\n",
    "\n",
    "cbind(Country = c(\"DK\", \"NOR\", \"SWE\"), DF = round(c(a1,a2,a3),4), ADF = round(c(b1,b2,b3),4), Lags = c(6,6,6), \n",
    "      DF.signf = ifelse(c(a1,a2,a3)< -3.73, TRUE, FALSE), ADF.signf = ifelse(c(b1,b2,b3)< -3.73, TRUE, FALSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Næste step i Engel-Granger fremgangsmådel er at estimere en fejlkorrektionsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 1.5** Kointegration - Johansen \n",
    "*Johansen metoden er et alternativ til Engle-Granger. Hvad er fordelene ved Johansen metoden?*\n",
    "\n",
    "ohansen-metoden er sammenlignet med Engle-Granger metoden mere effektiv. I Engle-Grangerframeworket skal man således i første omgang estimere den langsigtede ligevægt.  Estimeringen af den langsigtede ligevægt kan dog i de tilfælde, hvor du har mange variable være en anelse kompliceret. Det kan således være vanskeligt at afgøre, hvilken af de respektive variable der skal være den afhængige, og hvilke der skal være de forklarende/uafhængige. Dette er imidlertid en afgørende beslutning, da beslutningen omkring kointegration i Engle-Granger-frameworket i nogle tilfælde kan være følsom overfor denne beslutning. I Johansen-metoden anvender man i stedet blot trace-test $\\gamma_{trace}$ og maximum-eigenvalue-test $\\gamma_{max}$. Disse to tests anvendes til at bestemme, hvorvidt de respektive variable er kointegrerede og samtidig antallet af kointegrationsvektorer. En anden fordel er således, at konklusionen i Johansen-metoden bliver fundet i et trin, da den anvender sammenhængen mellem rangen af en matrix og dennes karakteristiske rødder. I modsætning hertil laver Engle-Granger-frameworket to forskellige estimeringer af både den langsigtede ligevægt og en ADF-test på fejlledet fra den regression. Der er således en større mulighed for at begå fejl i EG-frameworket.  \n",
    "\n",
    "Herudover giver Johansen-metoden også mulighed for at indføre deterministiske led, som en konstant eller trend, i kointegrationsrelationen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 1.6** Trace- og Max test\n",
    "*Gør kort rede for Trace test og Maximum Eigenvalue test, herunder hvorfor vi betragter egenværdier og hvordan de indgår i testene*\n",
    "\n",
    "I Trace-test og maximum-eigenvalue-test kigger man grundlæggende på rangen af \\pi-matricen, da rangen af denne matrice netop beskriver antallet af kointegrationsrelationer. I den forbindelse gælder det, at \\pi-matricen er en koefficientmatrice, der kan defineres ved:\n",
    "\n",
    "$$\\pi=\\alpha\\beta'$$\n",
    "\n",
    "I ovenstående udtryk er $\\alpha$ matricen der indeholder tilpasningsparametrene fra fejlkorrektionsmodellen, og $\\beta$ er kointegrationsvektoren. \n",
    "\n",
    "Det gælder desuden, at hvis ranken af $\\pi=0$, så har vi ingen kointegration mellem de respektive variable. I stedet er alle variablene integreret af 1. orden (I(1)-processer). Vi skal således tage differensen af de enkelte tidsserier før vi eksempelvis kan anvende dem i en VAR-model, men der er ikke tale om kointegration. Har vi derimod fuld rang; $r(\\pi)=n$, hvor n er udtryk for antallet af variable i kointegrationen, så vil alle de respektive variable være stationære, hvorfor der heller ikke er tale om kointegration. Vi har således i de tidligere opgaver arbejdet med tre variable, hvorfor fuld rang i dette tilfælde vil være 3. \n",
    "\n",
    "Hvis $\\pi$-matricen omvendt har reduceret rang; $0<rank(\\pi)=r<n$, så vil der være r kointegrationsrelationer og n-r stokastiske trends. I dette tilfælde vil der således være tale om kointegration mellem de respektive variable. Desuden ved vi at rangen af en matrice svarer til antallet af karakteristiske rødder eller egenværdier, der er forskellige fra 0. \n",
    "\n",
    "I praksis kan vi dog kun opnå estimater af $\\pi$ og de karakteristiske rødder. Trace- og maximum-eigenvalue-test tester netop for antallet af kointegrationsrelationer og antallet af karakteristiske rødder (egenværdier) der er forskellige fra nul. Teststatistikken for trace-testen og max-testen beregnes ved: \n",
    "\n",
    "$$\\gamma_{trace} (r)=-T\\sum_{i=r+1}^n ln(1-\\hat\\lambda_i)$$\n",
    "\n",
    "$$\\gamma_{max} (r,r+1)=-Tln(1-\\hat\\lambda_{r+1})$$\n",
    "\n",
    "I ovenstående udtryk er $\\hat\\lambda_i$ i de estimerede værdier af de karakteristiske rødder (egenværdier) og T er antallet af brugbare observationer. \n",
    "\n",
    "Trace-testen har en nulhypotese der siger, at antallet af kointegrationsvektorer eller kointegrationsrelationer er mindre end eller lig med r, og den alternative hypotese vil så være, at antallet af kointegrationsvektorer eller kointegrationsrelationer er større end r; \n",
    "\n",
    "$$H_0:rank(\\pi) \\leq r$$\n",
    "\n",
    "$$H_A:r=2,3,...,n$$\n",
    "\n",
    "Max-testen har en nulhypotese der siger, at antallet af kointegrationsvektorer er r mod den alternative hypotese omkring at antallet i stedet er $r+1$.\n",
    "\n",
    "$$H_0:rank(\\pi)=r$$\n",
    "\n",
    "$$H_A:rank(\\pi)=r+1$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### **Spørgsmål 1.7** Fortolk trace- og max test\n",
    "*I henhold til nedenstående output fra en Johansen kointegrationsanalyse af de 3 indeks bedes du argumentere for antallet af kointegrationsrelationer.*\n",
    "\n",
    "I dit svar bedes du skrive de anvendte test op (hvis du ikke allerede har gjort det) og kommentere pÂ nulhypotesen. Kommer du frem til en anden konklusion sammenlignet med EngleGranger tilgangen ovenfor?\n",
    "\n",
    "Først ser vi på trace testen, her konkluderer vi at:\n",
    "- Afviser klart en rang på  0\n",
    "- Kan ikke forkaste en rang på lig med eller større end 1 mod alternativet at den er større end to\n",
    "- Vi konkluderer altså at rangen er 1 og der findes en kointegrerende relation mellem de tre variabler\n",
    "\n",
    "Vi ser nu om max testen kan bekræfte hvad vi fandt:\n",
    "- Vi afviser at rangen er 0\n",
    "- vi kan ikke afvise at den er 1 mod alternativet at den er 2\n",
    "- Vi konkluderer derfor igen det samme at rangen er 1\n",
    "\n",
    "I forhold til Engel-Granger finder vi ikke et modsigende svar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(ca.jo(var[,-1], type = \"trace\", K = 5, ecdet = \"const\"))\n",
    "#summary(ca.jo(var[,-1], type = \"eigen\", K = 5, ecdet = \"const\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Opgave 2** Huspriser i Norden: Forecasting [15%]\n",
    "\n",
    "#### **Spørgsmål 2.1:** Du bedes gøre rede for den autoregressive model som beskriver data i perioden frem til fjerde kvartal 2005 (2005Q4) bedst muligt\n",
    "Husk at gøre rede for din fremgangsmåde og de begreber du anvender i din argumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEN <- var$DEN\n",
    "ldDEN <- diff(log(DEN))\n",
    "\n",
    "df <- data.frame(Dato = var$dato[-1], DEN = DEN[-1], ldDEN) %>% \n",
    "  subset(Dato<\"2006-01-01\")\n",
    "\n",
    "p <- df %>% \n",
    "  gather(variable, value, -Dato) %>% \n",
    "  ggplot(aes(Dato, value)) + \n",
    "  geom_line() + \n",
    "  facet_wrap(~variable, scales=\"free\") +\n",
    "  labs(title=\"Boligprisindeks samt log differentieret boligprisindeks\", \n",
    "       x=\"\", subtitle=\"Serien er begrænset til Q4 2005\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vi kan se på acf og pacf plottene at der er en væsentlig del af autokorrelation i tidsserien, og det er derfor relevant at modelere middelværdien i en AR, MA eller ARMA model.\n",
    "\n",
    "- ACF plottet viser et stort spike omkring periode 16, dette forsvinder næsten hvis manopdeler serien og tester i to dele, derfor antager vi det er tilfældigt\n",
    "\n",
    "- Jeg fitter 4 modeller, en AR(1), AR(2), AR(3) og en ARMA(1,1), af disse har AR(1) den laveste AIC på -579.29 og den næst laveste BIC på -570.85 (BIC straffer mange parametre i modellen hårdere end AIC). Jeg vælger dog en AR(2) eftersom denne har pænere residualer (og det er også det som auto.arima vælger).\n",
    "\n",
    "- Vi har desuden anvendt en Ljung-Box-test til at afgøre, om der er seriel korrelation i fejlledene op til lag 4, 8 og 12, og dette er ikke tilfældet. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a <- ggAcf(df$ldDEN) + labs(title=\"ACF\", subtitle=\"No model\")\n",
    "b <- ggPacf(df$ldDEN) + labs(title=\"PACF\", subtitle=\"No model\")\n",
    "\n",
    "m1 <- arima(df$ldDEN, order=c(1,0,0))\n",
    "m2 <- arima(df$ldDEN, order=c(2,0,0))\n",
    "m3 <- arima(df$ldDEN, order=c(3,0,0))\n",
    "m4 <- arima(df$ldDEN, order=c(1,0,1))\n",
    "#auto.arima(df$ldDEN)\n",
    "\n",
    "c <- ggAcf(m2$residuals) + labs(title=\"ACF\", subtitle=\"AR(2) residual\")\n",
    "d <- ggPacf(m2$residuals) + labs(title=\"PACF\", subtitle=\"AR(2) residual\")\n",
    "\n",
    "grid.arrange(a,b,c,d, nrow=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbind(Box.test(m1$residuals,lag=8,type=\"Ljung-Box\"), Box.test(m2$residuals,lag=8,type=\"Ljung-Box\"), \n",
    "      Box.test(m3$residuals,lag=8,type=\"Ljung-Box\"), Box.test(m4$residuals,lag=8,type=\"Ljung-Box\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 2.2:** På baggrund af dine estimater på de autoregressive koeficienter bedes du for god ordens skyld afgøre om modellen er stationær. Gør brug af et diagram med enhedscirklen.\n",
    "\n",
    "\n",
    "Parametrene fra modellen anvendes til at udregne rødderne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbind(m2$coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rødderne er inden for enhedscirklen da de er numerisk mindre end 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 <- 0.45163094\n",
    "a2 <- 0.17608406\n",
    "d <- a1^2 + 4*a2\n",
    "\n",
    "root_1 <- 0.5 * (a1 + d^0.5)\n",
    "root_2 <- 0.5 * (a1 - d^0.5)\n",
    "\n",
    "cbind(root_1, root_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 2.3:** På baggrund af din foretrukne autoregressive model bedes du beregne et (one-step ahead) forecast for 2006Q1. \n",
    "Beskriv hvordan du gør. Dernæst udvider du din stikprøve til også at indeholde 2006Q1 og estimerer pÂny dine autoregressive parametre for samme modelspecifikation, hvorefter du beregner et forecast for 2006Q2. Proceduren gentages indtil du har forecasts for 2006Q1, 2006Q2, 2006Q3 og 2006Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldDEN <- diff(log(DEN))\n",
    "\n",
    "#arima(ldDEN[1:123], order=c(2,0,0))$coef\n",
    "forecast1 <- 0.45163094 * ldDEN[123] + 0.17608406 * ldDEN[122] + 0.01753927\n",
    "forecast1a <- 0.45163094 * ldDEN[124] + 0.17608406 * ldDEN[123] + 0.01753927\n",
    "forecast1b <- 0.45163094 * ldDEN[125] + 0.17608406 * ldDEN[124] + 0.01753927\n",
    "forecast1c <- 0.45163094 * ldDEN[126] + 0.17608406 * ldDEN[125] + 0.01753927\n",
    "\n",
    "#arima(ldDEN[1:124], order=c(2,0,0))$coef\n",
    "forecast2 <- 0.45849043 * ldDEN[124] + 0.18233975 * ldDEN[123] + 0.01791534\n",
    "\n",
    "#arima(ldDEN[1:125], order=c(2,0,0))$coef\n",
    "forecast3 <- 0.45650047 * ldDEN[125] + 0.17829730 * ldDEN[124] + 0.01773019\n",
    "\n",
    "#arima(ldDEN[1:126], order=c(2,0,0))$coef\n",
    "forecast4 <- 0.45673044 * ldDEN[126] + 0.16577811 * ldDEN[125] + 0.01725091\n",
    "\n",
    "cbind(Quarter = c(1:4), \n",
    "      Model_A = c(forecast1, forecast1a,forecast1b,forecast1c), \n",
    "      Forecast = c(forecast1, forecast2, forecast3, forecast4), \n",
    "      Realised = c(ldDEN[124],ldDEN[125],ldDEN[126],ldDEN[127]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 <- arima(ldDEN[70:123], order=c(2,0,0))\n",
    "m2 <- arima(ldDEN[1:123], order=c(2,0,0))\n",
    "\n",
    "e1 <- predict(m1, n.ahead = 6)$pred - ldDEN[124:129]\n",
    "e2 <- predict(m2, n.ahead = 6)$pred  - ldDEN[124:129]\n",
    "\n",
    "dm.test(e1, e2, alternative = c(\"two.sided\", \"less\", \"greater\"), h = 1, power = 2)\n",
    "\n",
    "sum(abs(e1))\n",
    "sum(abs(e2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 2.4:** Plot de 4 forecast sammen med de realiserede værdier af det danske boligprisindeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <- data.frame(n = c(1:4), Forecast = c(forecast1,forecast2,forecast3,forecast4), \n",
    "                Real = c(ldDEN[124],ldDEN[125],ldDEN[126],ldDEN[127])) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value, linetype=variable)) +\n",
    "  geom_point(size=0.9) +\n",
    "  geom_line() +\n",
    "  labs(title=\"Forecast af log differencieret prisindeks med en AR(2)\", \n",
    "       x=\"Kvartaler i 2006\", y=\"værdi\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 2.5:** Diebold-Mariano testen\n",
    "Forestil dig, at vi ønsker at måle forecast performance for din foretrukne autoregressive model op mod forecasts fra en benchmark model. Gør rede for hvordan Diebold-Mariano testet kan anvendes til en sammenligning af din foretrukne model og benchmark modellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diebold-Mariano-testen er en test til at sammenligne forecasts fra to forskellige modeller, hvor man tager udgangspunkt i forecasts en periode frem. Man opstiller i DM-testen en værdi $d_i$, som beskriver forskellen på forecastfejlene i de to modeller i periode 𝑖: $d_i = g(e_{1i}-g(e_{2i})$. Man har således en benchmark-model og en model, som man tester denne benchmark-model imod. Middelværdien af denne forskel kan over hele tidsperioden beregnes ved: \n",
    "\n",
    "\n",
    "$$ \\hat{d}=\\frac{1}{H}\\sum^H_{i=1}[(g(e_{1i}-g(e_{2i})] $$\n",
    "\n",
    "𝐻 er i ovenstående udtryk antallet af forecasts. Nulhypotesen er i DM-testen, at de to modeller er lige gode til at forecaste tidsserien: $ H0: \\hat{d} = 0$. Hvis vi i forlængelse af dette kender $var(\\hat{d})$, så vil vi være i stand til at beregne en teststatistik ved $\\hat{d}/\\sqrt{var(\\hat{d})}$ og teste nulhypotesen omkring samme forecastevne i de to modeller. I praksis er denne test dog kompliceret, da estimeringen af $var(\\hat{d})$ er vanskelig. Hvis det gælder, at serien 𝑑𝑖 er serielt ukorreleret med stikprøvevariansen 𝛾0, så kan vi frembringe et estimat af $var(\\hat{d})$ ved $\\gamma_0/(H - 1)$. Bruger vi denne estimerede varians kan vi få en teststatistik for DM-testen ved at bruge formlen: \n",
    "\n",
    "$$ DM=\\frac{\\hat{d}}{\\sqrt{\\frac{\\gamma_0}{H-1}}} $$\n",
    " \n",
    "Denne DM-teststatistik følger en t-statistik med 𝐻 − 1 frihedsgrader, og kan derfor anvendes til at teste nulhypotesen. Forkastes denne nulhypotese er der således signifikant forskel på forecastevnen i de to modeller. Der findes dog en betydelig mængde litteratur omkring, hvordan standardafvigelsen af $\\hat{d}$ estimeres, og dette er typisk det mest komplicerede element i DM-testen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Opgave 3:** \"ARCH-in-mean\"[10%]\n",
    "\n",
    "#### **Spørgsmål 3.1:** Hvordan adskiller \"ARCH-in-mean\" modellen sig fra en traditional ARCH model? Skriv begge modeller op.\n",
    "\n",
    "\n",
    "**Almindelige ARCH-M model**\n",
    "\n",
    "Vi modelerer den betingede varians af fejlleddet\n",
    "$$ y_t = \\mu_t + \\varepsilon_t$$\n",
    "$$ \\varepsilon_t = v_t \\sqrt{h_t}$$\n",
    "$$ h_t = \\alpha_0 + \\sum^P_{i=1}\\alpha_i\\varepsilon^2_{t-i}$$\n",
    "\n",
    "**ARCH-M in mean**\n",
    "\n",
    "Påvirker middelværdien positivt ved høj varians, de anvendes i tilfælde hvor middelværdien afhænger af den betingede varians\n",
    "$$ y_t = \\mu_t + \\varepsilon_t$$\n",
    "$$\\mu_t = \\beta + \\delta h_t \\qquad \\delta>0$$\n",
    "$$ h_t = \\alpha_0 + \\sum^P_{i=1}\\alpha_i\\varepsilon^2_{t-i}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### **Spørgsmål 3.2:** Hvordan vil en GARCH(1,1)-in-mean model mon se ud? Skriv modellen op.\n",
    "\n",
    "\n",
    "**GARCH(1,1)-M**\n",
    "\n",
    "$$ y_t = \\mu_t + \\varepsilon_t$$\n",
    "$$\\mu_t = \\beta + \\delta h_t \\qquad \\delta>0 $$\n",
    "$$ h_t = \\alpha_0 + \\alpha_1\\varepsilon^2_{t-1} + \\beta_1 h_{t-1} \\qquad \\alpha_0>0 \\quad \\alpha_1 \\geq 0 \\quad \\beta_1 \\geq 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Opgave 4:** Vektorautoregressive modeller [50%]\n",
    "*Denne opgave består af 2 dele. Den første del er overvejende teoretisk beskrivende mens anden del i spørgsmål 4.6 har en mere implementerende karakter. Motivationen for temaet for denne opgave er den seneste tids kraftige prisfald i energipriserne. Den umiddelbare reaktion hos journalister og andet godtfolk er, at lavere energipriser giver anledning til højere beskæftigelse og højere vækst. Du bedes nu diskutere denne påstand teoretisk og vurdere den empiriske evidens.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 4.1:** Teoretisk: Energiprisfald\n",
    "*Diskuter med baggrund i økonomisk teori om et energiprisfald altid leder til højere beskæftigelse og vækst, eller om det kommer an på kilden til prisfaldet. Overvej at sondre mellem prisfald som følge af ændret aggregeret efterspørgsel efter energi (efterspørgselschok) eller ændret aggregeret energiudbud (udbudschok).*\n",
    "\n",
    "Hvis man tager udgangspunkt i et energiprisfald som følge af ændret aggregeret efterspørgsel, så vil det i et efterspørgsels-udbuds-diagram bevirke at efterspørgselskurven (grøn) vil bevæge sig mod venstre, da efterspørgslen vil falde. Denne bevægelse vil resultere i et nyt skæringspunkt (Q2,P2) mellem de to kurver, hvor prisen og outputtet/produktionen nu er lavere. Denne lavere produktion vil umiddelbart bevirke, at virksomhederne har behov for mindre arbejdskraft, hvorfor beskæftigelsen, den reale aktivitet og væksten umiddelbart vil falde. Denne sammenhæng er således illustreret i nedenstående figur 1. \n",
    "Har vi omvendt et scenarie, hvor energiprisfaldet er forårsaget af et udbudschok, så er konklusionen en anden. Her vil vi omvendt se, at udbudskurven (rød) vil bevæge sig mod højre, hvorfor prisen på energi vil falde og produktionen/mængden vil stige. Denne stigende produktion vil i stedet ved uændret produktivitet give anledning til stigende beskæftigelse, real aktivitet og vækst\n",
    "\n",
    "Ovenstående beskrivelser er dog eksempler på lukkede modeller, hvor man udelukkende kigger på energimarkedet. Man kunne således forestille sig, at de faldende energipriser i begge scenarier vil bevirke en større produktion, beskæftigelse og real aktivitet på en lang række andre markeder, hvor energi indgår som input i produktionen. Derfor kunne man argumentere for, at de negative effekter ved efterspørgselschokket vil blive opvejet af de positive effekter af prisfaldet på andre markeder, og at de positive effekter ved udbudschokket vil blive yderligere forstærket. De aggregerede effekter kan derfor være en anelse vanskelige at konkludere på, men det kunne dog tyde på, at effekterne overvejende er positive, hvis man åbner op for andre markeder.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spørgsmål 4.2** Impuls-respons-funktionen\n",
    "*Definer begrebet ”impulse-responses” og hvad man kan bruge impulse-respons analyse til. Giv eksempler på, hvilke impulse-responses, som vi kunne have interesse i at få belyst i relation til de faldende energipriser.*\n",
    "\n",
    "Impuls-respons-funktioner er grundlæggende funktioner der viser responsen på nuværende og fremtidige værdier af de respektive variable i SVAR-modellen af en enhedsændring i et af fejlledene (𝑢𝑡) i SVARmodellen, og samtidig antages det i disse IRF, at fejlledet igen er 0 i de efterfølgende perioder. De illustrerer således, hvordan et stød til en af variablene i SVAR-modellen, typisk på en standardafvigelse, vil påvirke de forskellige variable i modellen over en given tidsperiode.\n",
    "\n",
    "Det er desuden muligt at beregne disse impuls-responses eftersom vi ved at variablerne er stationære (eller kointegrerede), hvilket betyder de har en konstant varians, og at stød derfor over tid altid dør ud. \n",
    "\n",
    "I nedenstående matricer ses en grundlæggende SVAR fra Enders. Denne er simuleret og de 4 impulsfunktioner er plottet. Det ses her grundet Cholesky-dekompositionen at 𝑦𝑡 ikke har nogen samtidig effekt på 𝑧𝑡. \n",
    "\n",
    "Modsat ser vi at et chok i 𝑧𝑡 har en samtidig effekt på 𝑦𝑡, men som langsomt over ca. 20 perioder dør ud. \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} y_t \\\\ z_t \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 0.7 & 0.2 \\\\ 0.2 & 0.7 \\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} y_{t-1} \\\\ z_{t-1} \\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} e_{1t} \\\\ e_{2t} \\end{bmatrix}\n",
    "\\qquad\n",
    "B_0 = \\begin{bmatrix} 1 & 0.8 \\\\ 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Ud fra parametrene i SVAR modellen kan de også udregnes analytisk ved følgende formel:\n",
    "\n",
    "$$\n",
    "\\phi_i = \\frac{A^i_1}{1-b_{12}b_{21}}\n",
    "\\begin{bmatrix} 1 & b_{12} \\\\ b_{21} & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**I relation til energipriser (vi antager, at der her menes fossile brændstoffer):**\n",
    "\n",
    "Et eksempel kunne være en SVAR model med oliepris, inflation og real BNP, da det kunne være interessant at se, hvordan ændringer i olieprisen påvirker inflationsudviklingen og det reale BNP. Når vi benytter en strukturel model, er der dog samtidige effekter i variablerne, hvilket giver et problem eftersom modellen er underidentificeret. Dette løses med en Cholesky dekomposition men her vil spørgsmålet være i hvilken rækkefølge variablerne skal ordnes i. Dette er ikke ligegyldigt for konklusionerne, og variablerne skal ordnes fra mest eksogen til mindst, og her skal økonomisk teori anvendes.\n",
    "\n",
    "Der kan i denne simple model argumenteres for at olieprisen er meget eksogent, altså at BNP og inflation ikke har samtidige effekter på denne, men rangordenen mellem inflation og real BNP er mere åben. Et forslag til en rækkefølge kunne f.eks. være: real BNP, inflation, oliepris. Denne orden er ud fra logikken om at inflationen er mere træg end real BNP. En sådan model vil så kunne bruges til at undersøge et stød i olieprisen, og dette støds effekt på inflationen eller væksten gennem impuls-respons funktionen.\n",
    "\n",
    "Det er dog vigtigt at huske at der i en analyse at denne karakter, selvom responsen er meget interessant, vil være en høj grad af kontrafaktisk analyse. Dette er eftersom parametrene er estimeret i en periode uden det udførte chok, og resultatet derfor må være ”alt andet lige”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly <- read_delim(\"C:/Users/larsn/Desktop/quarterly.csv\", \n",
    "    \";\", \n",
    "    col_types = cols(\n",
    "  Date = col_double(),\n",
    "  `World Oil Production` = col_double(),\n",
    "  `Aggregate Industrial Production` = col_double(),\n",
    "  `Average World Price of Oil` = col_double(),\n",
    "  `Inventories of Oil (OECD)` = col_double(),\n",
    "  `Global Activity` = col_double(),\n",
    "  Year = col_integer(),\n",
    "  Quarter = col_integer()\n",
    "),\n",
    "    escape_double = FALSE, \n",
    "    locale = locale(decimal_mark = \",\"), \n",
    "    trim_ws = TRUE)\n",
    "\n",
    "quarterly$Date <- seq(as.Date(\"1985-01-01\"), length = 88, by = \"quarter\")\n",
    "quarterly$Year <- NULL\n",
    "quarterly$Quarter <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Spørgsmål 4.6:** Kvantitativt: 5 dimensionel VAR\n",
    "*Brug data fra Excel filen benævnt dataExam2019.xlsx fra fanebladet \"Quarterly\". Data er i log-differencer. Antag fravær af evt. tidsvarierende volatilitet i VAR residualerne eller lignende.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=4, warn=-1)\n",
    "\n",
    "p <- quarterly %>% \n",
    "  gather(variable, value, -Date) %>% \n",
    "  ggplot(aes(Date, value)) +\n",
    "  geom_line() + \n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  labs(title=\"5-dimensional VAR(p)\", x=\"\", y=\"Logdifference\") + \n",
    "  facet_wrap(~variable, scale=\"free\", nrow=2)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Gøre rede for hvordan du vil bestemmet antallet af lags i den pågældende VAR.\n",
    "\n",
    "- VI kigger på AIC og BIC, ud fra AIC ville vi vælge en model med 6 lags, men BIC foretrækker en med 1 lag, for at forsimple de efterfølgende vælger vi en model med 1 lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1<- AIC(VAR(quarterly[,-1], p=1, type=\"none\"))\n",
    "a2 <- AIC(VAR(quarterly[,-1], p=2, type=\"none\"))\n",
    "a3 <- AIC(VAR(quarterly[,-1], p=3, type=\"none\"))\n",
    "a4 <- AIC(VAR(quarterly[,-1], p=4, type=\"none\"))\n",
    "a5 <- AIC(VAR(quarterly[,-1], p=5, type=\"none\"))\n",
    "a6 <- AIC(VAR(quarterly[,-1], p=6, type=\"none\"))\n",
    "\n",
    "b1 <- BIC(VAR(quarterly[,-1], p=1, type=\"none\"))\n",
    "b2 <- BIC(VAR(quarterly[,-1], p=2, type=\"none\"))\n",
    "b3 <- BIC(VAR(quarterly[,-1], p=3, type=\"none\"))\n",
    "b4 <- BIC(VAR(quarterly[,-1], p=4, type=\"none\"))\n",
    "b5 <- BIC(VAR(quarterly[,-1], p=5, type=\"none\"))\n",
    "b6 <- BIC(VAR(quarterly[,-1], p=6, type=\"none\"))\n",
    "\n",
    "df <- data.frame(Model=c(1:6), AIC = c(a1, a2, a3, a4,a5,a6), BIC = c(b1,b2,b3,b4,b5,b6))\n",
    "as.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Angiv alle autoregressive parametre fra den estimerede VAR og den estimerede varians-kovarians matrice for residualerne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- quarterly[,-1]\n",
    "colnames(data) <- c(\"Oil Production\", \"Industrial Production\", \"Oil Price\", \"Oil Inventories\", \"Global Activity\")\n",
    "fit <- VAR(data, p=1, type=\"none\")\n",
    "round(Acoef(fit)[[1]],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covm <- summary(fit)$covres\n",
    "round(covm,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Opgave 2:** Beregn og illustrer konkret følgende impulse responses over minimum 5 perioder men gerne 10\n",
    "\n",
    "(a) Olieprisens respons som følge af et chok til olieproduktionen af størrelsen 1 standardafvigelse.\n",
    "\n",
    "(b) Olieprisens respons som følge af et chok til olielagrene.\n",
    "\n",
    "(c) Industriproduktionens respons som følge af et chok til olieprisen.\n",
    "\n",
    "(d) Olieprisens respons som følge af et chok til den globale økonomiske aktivitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 <- diag(5)\n",
    "a1 <- as.matrix(Acoef(fit)[[1]]) %^% 1\n",
    "a2 <- as.matrix(Acoef(fit)[[1]]) %^% 2\n",
    "a3 <- as.matrix(Acoef(fit)[[1]]) %^% 3\n",
    "a4 <- as.matrix(Acoef(fit)[[1]]) %^% 4\n",
    "a5 <- as.matrix(Acoef(fit)[[1]]) %^% 5\n",
    "a6 <- as.matrix(Acoef(fit)[[1]]) %^% 6\n",
    "a7 <- as.matrix(Acoef(fit)[[1]]) %^% 7\n",
    "a8 <- as.matrix(Acoef(fit)[[1]]) %^% 8\n",
    "a9 <- as.matrix(Acoef(fit)[[1]]) %^% 9\n",
    "a10 <- as.matrix(Acoef(fit)[[1]]) %^% 10\n",
    "\n",
    "dff <- data.frame(n = c(0:10),\n",
    "                  A = c(a0[3,1], a1[3,1],a2[3,1],a3[3,1],a4[3,1],a5[3,1],a6[3,1],a7[3,1],a8[3,1],a9[3,1],a10[3,1]),\n",
    "                  B = c(a0[3,4], a1[3,4],a2[3,4],a3[3,4],a4[3,4],a5[3,4],a6[3,4],a7[3,4],a8[3,4],a9[3,4],a10[3,4]),\n",
    "                  C = c(a0[2,3], a1[2,3],a2[2,3],a3[2,3],a4[2,3],a5[2,3],a6[2,3],a7[2,3],a8[2,3],a9[2,3],a10[2,3]),\n",
    "                  D = c(a0[3,5], a1[3,5],a2[3,5],a3[3,5],a4[3,5],a5[3,5],a6[3,5],a7[3,5],a8[3,5],a9[3,5],a10[3,5]))\n",
    "round(as.matrix(dff),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=4.5)\n",
    "#chol(covm)\n",
    "\n",
    "a <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Production)\n",
    "a$n <- c(1:31)\n",
    "pa <- a %>% \n",
    "  dplyr::select(Oil.Price, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"A) Shock in world oil production\", x=\"\", y=\"\")\n",
    "\n",
    "b <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Inventories)\n",
    "b$n <- c(1:31)\n",
    "pb <- b %>% \n",
    "  dplyr::select(Oil.Price, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"B) Shock to the inventories of oil\", x=\"\", y=\"\")\n",
    "\n",
    "c <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Price)\n",
    "c$n <- c(1:31)\n",
    "pc <- c %>% \n",
    "  dplyr::select(Industrial.Production, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"C) Shock to the world price of oil\", x=\"\", y=\"\")\n",
    "\n",
    "d <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Global.Activity)\n",
    "d$n <- c(1:31)\n",
    "pd <- d %>% \n",
    "  dplyr::select(Oil.Price, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"D) Shock to the global activity\", x=\"\", y=\"\")\n",
    "\n",
    "grid.arrange(pa,pb,pc,pd, nrow=2, left=\"Period change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Hvis tiden tillader det og alle andre spørgsmÂl er (forsøgt) besvaret, sÂ overvej at akkumulere de beregnede impulse responses over tid, idet det kan vÊre lettere at vurdere summen af vækstraterne (angivet ved log-differences). Konkret kan du blot akkumulere det beregnede impulse response i successivt over tid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Production)\n",
    "a$n <- c(1:31)\n",
    "pa <- a %>% \n",
    "  mutate(Oil.Price.acc = cumsum(Oil.Price)) %>% \n",
    "  dplyr::select(Oil.Price.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"A) Shock in world oil production\", x=\"\", y=\"\")\n",
    "\n",
    "b <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Inventories)\n",
    "b$n <- c(1:31)\n",
    "pb <- b %>% \n",
    "  mutate(Oil.Price.acc = cumsum(Oil.Price)) %>% \n",
    "  dplyr::select(Oil.Price.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"B) Shock to the inventories of oil\", x=\"\", y=\"\")\n",
    "\n",
    "c <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Price)\n",
    "c$n <- c(1:31)\n",
    "pc <- c %>% \n",
    "  mutate(Industrial.Production.acc = cumsum(Industrial.Production)) %>% \n",
    "  dplyr::select(Industrial.Production.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"C) Shock to the world price of oil\", x=\"\", y=\"\")\n",
    "\n",
    "d <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Global.Activity)\n",
    "d$n <- c(1:31)\n",
    "pd <- d %>% \n",
    "  mutate(Oil.Price.acc = cumsum(Oil.Price)) %>% \n",
    "  dplyr::select(Oil.Price.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"D) Shock to the global activity\", x=\"\", y=\"\")\n",
    "\n",
    "grid.arrange(pa,pb,pc,pd, nrow=2, left=\"Accumulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 3: Kommenter på dine beregnede impulse responses. Er de som forventet og er de plausible?\n",
    "\n",
    "Vi kigger på de akkumulerede response til shoksne:\n",
    "\n",
    "A) Et chock i produktionen af olie i en periode øger prisen meget hurtigt, men ændringen dør hurtigt ud, det giver god inituitiv mening\n",
    "\n",
    "B) Et chock til olielagrene øger prisen, men den falder langsomt igen, og den samlede effekt er negativ, det giver måske mindre mening, men det giver mening at prisstigningen ikke er permanent \n",
    "\n",
    "C) Et chock i olieprisen i en periode påvirker produktionen permament, det giver god mening\n",
    "\n",
    "D) Et chock i den globale aktivitet virker negativt og permanent, det giver også god mening at det er over længere tid da shocks i den globale aktivitet sjældent vil kunne være lige så pludselige som chocks i olieprisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Production)\n",
    "a$n <- c(1:31)\n",
    "pa <- a %>% \n",
    "  mutate(Oil.Price.acc = cumsum(Oil.Price)) %>% \n",
    "  dplyr::select(Oil.Price.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"A) Shock in world oil production\", x=\"\", y=\"\")\n",
    "\n",
    "b <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Inventories)\n",
    "b$n <- c(1:31)\n",
    "pb <- b %>% \n",
    "  mutate(Oil.Price.acc = cumsum(Oil.Price)) %>% \n",
    "  dplyr::select(Oil.Price.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"B) Shock to the inventories of oil\", x=\"\", y=\"\")\n",
    "\n",
    "c <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Oil.Price)\n",
    "c$n <- c(1:31)\n",
    "pc <- c %>% \n",
    "  mutate(Industrial.Production.acc = cumsum(Industrial.Production)) %>% \n",
    "  dplyr::select(Industrial.Production.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"C) Shock to the world price of oil\", x=\"\", y=\"\")\n",
    "\n",
    "d <- as.data.frame(irf(fit, n.ahead = 30, ortho = F)$irf$Global.Activity)\n",
    "d$n <- c(1:31)\n",
    "pd <- d %>% \n",
    "  mutate(Oil.Price.acc = cumsum(Oil.Price)) %>% \n",
    "  dplyr::select(Oil.Price.acc, n) %>% \n",
    "  gather(variable, value, -n) %>% \n",
    "  ggplot(aes(n, value)) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +\n",
    "  facet_wrap(~variable) +\n",
    "  labs(title=\"D) Shock to the global activity\", x=\"\", y=\"\")\n",
    "\n",
    "grid.arrange(pa,pb,pc,pd, nrow=2, left=\"Accumulated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
